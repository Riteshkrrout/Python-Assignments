{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Question1 Importing the packages\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import load_digits\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = load_digits()\n",
    "X = digit.data\n",
    "Y = digit.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape , Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3efa156860>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3efdd0f7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##question2\n",
    "plt.imshow(x[5].reshape(8,8),cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##question 3\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Question 4\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5(a)classification accuarcy means no. of cross predictions made as a ratio of all predictions made.\n",
    "pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "0         1          1\n",
       "1         0          0\n",
       "2         6          6\n",
       "3         4          4\n",
       "4         3          3\n",
       "5         8          8\n",
       "6         0          0\n",
       "7         9          9\n",
       "8         7          7\n",
       "9         1          1\n",
       "10        1          1\n",
       "11        3          3\n",
       "12        2          2\n",
       "13        3          3\n",
       "14        9          9\n",
       "15        8          8\n",
       "16        4          4\n",
       "17        6          6\n",
       "18        7          7\n",
       "19        9          9\n",
       "20        0          0\n",
       "21        9          9\n",
       "22        5          5\n",
       "23        9          9\n",
       "24        5          9\n",
       "25        4          4\n",
       "26        6          6\n",
       "27        3          3\n",
       "28        6          6\n",
       "29        6          6\n",
       "..      ...        ...\n",
       "510       1          1\n",
       "511       5          5\n",
       "512       1          2\n",
       "513       7          7\n",
       "514       8          8\n",
       "515       2          2\n",
       "516       5          5\n",
       "517       5          5\n",
       "518       9          9\n",
       "519       5          5\n",
       "520       1          1\n",
       "521       1          8\n",
       "522       7          7\n",
       "523       0          0\n",
       "524       8          8\n",
       "525       3          3\n",
       "526       3          3\n",
       "527       8          8\n",
       "528       6          6\n",
       "529       7          7\n",
       "530       0          0\n",
       "531       2          2\n",
       "532       1          5\n",
       "533       6          6\n",
       "534       1          1\n",
       "535       6          6\n",
       "536       8          8\n",
       "537       5          5\n",
       "538       1          8\n",
       "539       3          3\n",
       "\n",
       "[540 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({\"Predicted\":pred,\"Actual\":Y_test})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold= model_selection.KFold(n_splits=10,random_state=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90555556, 0.95      , 0.89444444, 0.91666667, 0.94444444,\n",
       "       0.97222222, 0.97777778, 0.95530726, 0.8603352 , 0.93854749])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=model_selection.cross_val_score(reg,X,Y,cv=kfold,scoring='accuracy')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931530105524519"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45798961, -0.14435058, -0.61749705, -0.27323142, -0.27594697,\n",
       "       -0.12815811, -0.11024468, -0.1233365 , -0.62592303, -0.68553964])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 5(b) Logarithmic loss means performancemetrics for evaluating the predictions.\n",
    "results=model_selection.cross_val_score(reg,X,Y,cv=kfold,scoring='neg_log_loss')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3442217575018163"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0,  0,  0,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0, 53,  1,  0,  0,  1,  0,  0, 10,  1],\n",
       "       [ 0,  1, 53,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 48,  0,  1,  0,  0,  2,  0],\n",
       "       [ 0,  0,  0,  0, 57,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 52,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0, 60,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 54,  1,  2],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  1, 48,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  0,  1, 48]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 5(f)confusion matrix means presentation of the accuarcy of a model.\n",
    "confusion_matrix(Y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99        41\n",
      "          1       0.95      0.80      0.87        66\n",
      "          2       0.98      0.98      0.98        54\n",
      "          3       1.00      0.94      0.97        51\n",
      "          4       1.00      1.00      1.00        57\n",
      "          5       0.95      0.96      0.95        54\n",
      "          6       1.00      1.00      1.00        60\n",
      "          7       0.98      0.95      0.96        57\n",
      "          8       0.77      0.96      0.86        50\n",
      "          9       0.91      0.96      0.93        50\n",
      "\n",
      "avg / total       0.95      0.95      0.95       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 5(g)classification report function display the precision, recall,f1 score and support for each class.\n",
    "print (classification_report(Y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40105499, 0.63102463, 0.57072313, 0.59629035, 0.54519634,\n",
       "       0.67174215, 0.61763556, 0.47611004, 0.4236549 , 0.41044286])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Question 5(c)R2 metrics provides an indication of goodness of a set of predictions to the actual values.\n",
    "reg1 = LinearRegression()\n",
    "results=model_selection.cross_val_score(reg1,X,Y,cv=kfold,scoring='r2')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5343874961263955"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.76232318, -1.33110792, -1.55360439, -1.51943658, -1.50040068,\n",
       "       -1.30773649, -1.41940728, -1.60049753, -1.62693098, -1.75390435])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 5(d)Mean absolute error means the sum of the absolute differences b/w predictions and actual values.\n",
    "results=model_selection.cross_val_score(reg1,X,Y,cv=kfold,scoring='neg_mean_absolute_error')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5375349366952842"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.08763116, -2.93563178, -3.5440648 , -3.35720712, -3.61041109,\n",
       "       -2.77252253, -3.06878144, -4.29164324, -4.76128221, -4.75789407])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 5(e)Mean squared error means provides a gross idea of the magnitude of error.\n",
    "results=model_selection.cross_val_score(reg1,X,Y,cv=kfold,scoring='neg_mean_squared_error')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.81870694491852"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
